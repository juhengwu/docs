---
title: "Datasets"
description: "Prompt datasets for offline evaluation and safety testing."
---

Know Your AI provides curated datasets built for evaluating and stress-testing LLM products.
These datasets include prompts trained and refined by machine learning engineers to uncover
model vulnerabilities and bypass weak guardrails in a controlled, offline setting.

## What you can expect

- **Attack-focused prompts** crafted to expose safety and policy gaps
- **Benchmark-style suites** for consistent, repeatable evaluation runs
- **Community-tested datasets** sourced from the Prompt Market

## Attack methods included

We include datasets based on multiple attack strategies, such as:

- Adaptive
- ABJ
- AutoDan
- GCG

## How to use them

1. Open **Product** in your workspace.
2. Choose a dataset from the Prompt Market.
3. Connect your product API and run an offline evaluation.
4. Review results with **LLM as the Judge** and **Human Annotate**.

If you want a custom dataset, reach out to the Know Your AI team.
